Feature Engineering
===================

.. automodule:: bitcoin_scalper.core.feature_engineering
   :members:
   :undoc-members:
   :show-inheritance:

Features générées
-----------------

- rsi
- macd, macd_signal, macd_diff
- ema_21, ema_50, sma_20
- bb_high, bb_low, bb_width
- atr, supertrend, vwap
- tickvol (copie de volume si absent)
- close_sma_3 (SMA 3 sur close)
- atr_sma_20 (SMA 20 sur ATR)

Exemple d'utilisation
---------------------

.. code-block:: python

   from bitcoin_scalper.core.feature_engineering import FeatureEngineering
   import pandas as pd
   df = pd.DataFrame({
       'close': [100, 101, 102],
       'high': [101, 102, 103],
       'low': [99, 100, 101],
       'volume': [10, 12, 11]
   })
   fe = FeatureEngineering()
   df_feat = fe.add_indicators(df)
   print(df_feat.columns)

Sécurité temporelle
------------------

- Tous les indicateurs sont décalés d'une bougie (shift(1)) pour éviter tout look-ahead bias.
- VWAP est calculé de façon cumulative et décalée.
- Aucun indicateur ne regarde le futur : sécurité stricte pour le ML et le backtest.

.. note::
   Depuis le 2024-06-11, la méthode ``add_indicators`` ajoute automatiquement les indicateurs avancés suivants (multi-timeframe, tous décalés d'une bougie pour éviter le look-ahead bias) :

   - Volatilité : Keltner Channels, Donchian Channels, Chandelier Exit, Ulcer Index
   - Volume : MFI, OBV, Accumulation/Distribution, Chaikin Money Flow
   - Momentum : TSI, CCI, Williams %R, Stochastic RSI, Ultimate Oscillator, ROC
   - Trend : ADX, DMI, Ichimoku, Parabolic SAR, PPO

   Ces indicateurs enrichissent fortement le pipeline ML pour la détection de signaux robustes.

.. note::
   Depuis le 2024-06-11, la méthode ``add_features`` ajoute automatiquement des features de contexte avancées :

   - Z-score généralisé sur plusieurs fenêtres (5, 20, 50, 100) pour close, high, low, volume
   - Distance à la bande de Bollinger (écart à bb_high, bb_low, bb_width)
   - Distance au plus haut/bas N périodes (5, 20, 50, 100)
   - Encodage temporel enrichi (minute, heure, jour, semaine, mois, quarter, year, encodage cyclique)
   - Position relative dans la journée/semaine/mois

   Ces features permettent d'apporter un contexte de marché et temporel robuste au pipeline ML.

Analyse d'importance des features
--------------------------------

Une fonction dédiée permet d'analyser l'importance des features (gain, split, SHAP) après chaque entraînement de modèle (LightGBM/XGBoost) :

- Génération automatique de rapports PNG/HTML (bar plot, summary plot SHAP)
- Export dans le dossier data/features/
- Utilisation recommandée après chaque entraînement pour guider l'itération sur le feature engineering.

Tests unitaires
---------------

Des tests automatisés (pytest) valident la présence et la cohérence de chaque indicateur avancé ajouté. Voir ``tests/core/mac/test_feature_engineering.py`` pour la liste exhaustive et les assertions de robustesse.

Sélection automatique des features
----------------------------------

La fonction ``select_features_by_importance`` permet de sélectionner automatiquement les features les plus importantes (par gain/split ou SHAP) après chaque entraînement de modèle :

- Prend en entrée un modèle ML et un DataFrame de features
- Retourne la liste des features à conserver (top N)
- Permet d'itérer rapidement sur le feature set et d'automatiser la suppression des features inutiles 

Génération de labels multi-horizon
----------------------------------

La fonction ``generate_multi_horizon_labels`` permet de générer automatiquement les labels pour plusieurs horizons de prédiction (5, 10, 15, 30 min) :

- Ajoute les colonnes target_5m, target_10m, target_15m, target_30m au DataFrame
- Permet d'évaluer la robustesse du modèle sur différents horizons de marché 

Labeling : support des différents types de seuils
-------------------------------------------------

La fonction ``generate_labels`` permet de choisir le type de seuil pour la génération des labels :

- ``threshold_type="std"`` : seuil dynamique basé sur la volatilité locale (rolling std)
- ``threshold_type="quantile"`` : seuils basés sur les quantiles des retours futurs (ex : 80e/20e percentile)
- ``threshold_type="spread_fee"`` : seuil absolu (spread+frais)

Cela permet de tester la robustesse du modèle selon différentes définitions de « signal ».

Labeling : mode actionnable (gain net après frais/slippage)
----------------------------------------------------------

La fonction ``generate_labels`` permet de générer des labels « actionnables » :

- ``threshold_type="actionnable"`` : le label dépend du gain net après application d'un spread, de frais et d'un slippage paramétrables
- Les classes sont : 1 (gain net > 0), -1 (gain net < 0), 0 (sinon)
- Permet d'aligner le signal ML sur la réalité du trading après coûts 

Analyse de la distribution des labels
-------------------------------------

La fonction ``analyze_label_distribution`` permet d'analyser la distribution des labels (comptage, pourcentage) :

- Génère un rapport PNG (bar plot) et un rapport JSON (statistiques)
- Alerte si la distribution est très déséquilibrée (>90% d'une classe)
- Permet de valider la pertinence métier des labels avant entraînement 

Vérification de la cohérence temporelle
---------------------------------------

La fonction ``check_temporal_consistency`` permet de valider la qualité temporelle des datasets :

- Détecte les fuites d'information (look-ahead) sur les colonnes target/future
- Détecte les doublons, le désordre, les gaps, les timestamps dans le futur
- Génère un rapport JSON sur les incohérences détectées
- Permet de garantir l'absence de fuite d'information avant tout entraînement ML 

Audit global de la qualité des données
--------------------------------------

La méthode ``audit_data_quality`` de DataCleaner permet d'orchestrer tout le pipeline qualité :

- Nettoyage avancé, correction des outliers/trous, vérification de la cohérence temporelle, analyse de la distribution des labels
- Génère un rapport global JSON et des sous-rapports détaillés (logs, PNG, etc.)
- Permet d'automatiser l'audit qualité avant tout entraînement ou backtest 

Split temporel robuste (train/val/test)
--------------------------------------

La fonction ``temporal_train_val_test_split`` permet de découper un DataFrame indexé par datetime :

- Split par bornes explicites (dates) ou proportions (train/val/test)
- Exclusion automatique des derniers points de train/val pour éviter toute fuite sur les labels futurs (multi-horizon)
- Génère un rapport JSON détaillé (dates, tailles, indices, sécurité, absence d'overlap)
- Sécurité : aucune intersection entre les splits, vérification de l'absence de fuite
- Utilisation recommandée avant tout entraînement ML ou backtest 

Génération automatique des folds (validation croisée temporelle)
--------------------------------------------------------------

Les fonctions ``generate_time_series_folds`` et ``generate_purged_kfold_folds`` permettent de générer automatiquement les folds pour la validation croisée :

- TimeSeriesSplit : découpage standard scikit-learn, pas d'overlap, pas de fuite temporelle
- PurgedKFold : découpage chronologique avec fenêtre de purge anti-fuite entre train et validation
- Génération d'un rapport JSON détaillé (bornes, tailles, indices, sécurité)
- Sécurité : aucune intersection entre train/val, vérification de la purge
- Utilisation recommandée pour le tuning, la validation robuste et l'audit ML 

Orchestration du pipeline ML (split/train/test/report)
-----------------------------------------------------

La fonction ``run_ml_pipeline`` permet d'orchestrer tout le pipeline ML :

- Split temporel robuste, génération des folds, entraînement LightGBM/XGBoost, évaluation sur validation/test
- Génération automatique de rapports (JSON, PNG, CSV) : métriques, courbes de confusion, importance des features
- Sécurité anti-fuite, reproductibilité, logging structuré
- Utilisation recommandée pour l'entraînement, le tuning et l'audit des modèles ML 

Tuning avancé des hyperparamètres
---------------------------------

La fonction ``tune_model_hyperparams`` permet d'optimiser automatiquement les hyperparamètres des modèles ML :

- Support grid search, random search, Optuna (si installé)
- Validation croisée temporelle (TimeSeriesSplit), early stopping, logging structuré
- Génération automatique de rapports (JSON, CSV, PNG) : meilleurs paramètres, tous les essais, courbe des scores, importance des features
- Sécurité, reproductibilité, auditabilité
- Utilisation recommandée pour le tuning, la recherche de robustesse et l'audit des modèles ML 

Exécution temps réel / simulation
---------------------------------

La classe ``RealTimeExecutor`` permet d'exécuter un modèle ML en temps réel ou en mode simulation :

- Support du mode live (API exchange/mock) et du mode simulation (replay historique)
- Gestion du portefeuille, des signaux, de la latence, du reporting (CSV, PNG)
- Sécurité, auditabilité, reproductibilité
- Utilisation recommandée pour le paper trading, le monitoring, la validation en conditions réelles 